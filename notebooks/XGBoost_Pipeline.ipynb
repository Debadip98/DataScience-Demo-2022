{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488fd2eb",
   "metadata": {},
   "source": [
    "# XGBoost End-to-End Machine Learning Pipeline\n",
    "\n",
    "This notebook demonstrates a complete machine learning workflow using XGBoost, including:\n",
    "- Data loading and exploration\n",
    "- Preprocessing and feature engineering\n",
    "- Model training with hyperparameter tuning\n",
    "- Evaluation and explainability\n",
    "- Unit testing with pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc6177a",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup\n",
    "\n",
    "Install and verify required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Random seeds set for reproducibility\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "\n",
    "import numpy as np\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "\n",
    "import xgboost as xgb\n",
    "print(f\"xgboost: {xgb.__version__}\")\n",
    "\n",
    "from sklearn import __version__ as sklearn_version\n",
    "print(f\"scikit-learn: {sklearn_version}\")\n",
    "\n",
    "import matplotlib\n",
    "print(f\"matplotlib: {matplotlib.__version__}\")\n",
    "\n",
    "import seaborn\n",
    "print(f\"seaborn: {seaborn.__version__}\")\n",
    "\n",
    "print(\"\\n✓ All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff64b8",
   "metadata": {},
   "source": [
    "## Section 2: Import Libraries\n",
    "\n",
    "Import all required libraries for the ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3160e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, SimpleImputer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c43515e",
   "metadata": {},
   "source": [
    "## Section 3: Load Dataset\n",
    "\n",
    "Load and explore the breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.Series(cancer.target, name='target')\n",
    "\n",
    "# Create combined dataframe\n",
    "df = X.copy()\n",
    "df['target'] = y\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed2847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum().sum())\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"\\nClass proportions:\")\n",
    "print(df['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899bca6",
   "metadata": {},
   "source": [
    "## Section 4: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Analyze and visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Target distribution\n",
    "df['target'].value_counts().plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4'])\n",
    "axes[0].set_title('Target Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['Malignant (0)', 'Benign (1)'], rotation=0)\n",
    "\n",
    "# Target proportions\n",
    "df['target'].value_counts(normalize=True).plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\n",
    "axes[1].set_title('Class Proportions', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Target visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "fig, axes = plt.subplots(4, 4, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(X.columns[:16]):\n",
    "    axes[idx].hist(X[col], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(col, fontsize=9)\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature distributions visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5a3d6a",
   "metadata": {},
   "source": [
    "## Section 5: Preprocessing & Feature Engineering\n",
    "\n",
    "Define preprocessing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d920cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric features ({len(numeric_features)}): {numeric_features[:5]}...\")\n",
    "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "print(\"\\n✓ Preprocessor defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59756d",
   "metadata": {},
   "source": [
    "## Section 6: Train/Validation Split & Cross-Validation Strategy\n",
    "\n",
    "Prepare data for model training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
